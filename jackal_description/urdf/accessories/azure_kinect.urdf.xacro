<?xml version="1.0"?>
<!--
  This file is copied largely from Microsoft's azure_kinect.urdf.xacro, found in https://github.com/microsoft/Azure_Kinect_ROS_Driver

  MIT License

Copyright (c) Microsoft Corporation. All rights reserved.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE
-->
<robot xmlns:xacro="http://www.ros.org/wiki/xacro">
  <xacro:macro name="azure_kinect_mount" params="prefix topic parent_link">

    <xacro:macro name="azure_kinect" params="
                      frame:=kinect       topic:=kinect
                      min_range:=0.5      max_range:=5.46
                      update_rate:=30
                      h_fov:=1.3089958333333334 v_fov:=1.1344630555555555
                      width:=576 height:=640">

      <!-- this link is the origin for the camera data and corresponds to the front visor of the camera -->
      <link name="${frame}">
        <visual>
          <origin xyz="-0.0128 0. 0." />
          <geometry>
            <box size="0.026 0.101 0.037" />
          </geometry>
          <material name="black" />
        </visual>
      </link>

      <link name="${frame}_body">
        <visual>
          <origin xyz="0. 0. 0." />
          <geometry>
            <box size="0.0994 0.0996 0.023" />
          </geometry>
          <material name="white" />
        </visual>
      </link>

      <link name="${frame}_base">
        <visual>
          <origin xyz="-0.013 0. 0." />
          <geometry>
            <box size="0.026 0.103 0.039" />
          </geometry>
          <material name="medium_grey" />
        </visual>
      </link>

      <joint name="${frame}_base_to_body" type="fixed">
        <parent link="${frame}_base" />
        <child link="${frame}_body" />
        <origin xyz="-0.0757 0. 0.008" rpy="0. 0. 0." />
      </joint>

      <joint name="${frame}_base_to_visor" type="fixed">
        <parent link="${frame}_base" />
        <child link="${frame}" />
        <origin xyz="0. 0. 0." rpy="0. 0. 0." />
      </joint>

      <!--
        The gazebo plugin aligns the depth data with the Z axis, with X=left and Y=up
        ROS expects the depth data along the X axis, with Y=left and Z=up
        This link only exists to give the gazebo plugin the correctly-oriented frame
      -->
      <link name="${prefix}_kinect_gazebo" />
      <joint name="${prefix}_kinect_gazebo_joint" type="fixed">
        <parent link="${frame}"/>
        <child link="${frame}_gazebo"/>
        <origin xyz="0 0 0" rpy="-1.5707963267948966 0 -1.5707963267948966"/>
      </joint>

      <!--
        This isn't a 100% accurate representation of the Azure Kinect's data, but it's reasonably close.
        The color data on the real camera has a 90x59 degree FOV, and the depth data is the full vision
        cone approximated as a hexagon within the frame.
        But for now the OpenNI kinect plugin is the closest analogue
      -->
      <gazebo reference="${frame}">
        <turnGravityOff>true</turnGravityOff>
        <sensor type="depth" name="${prefix}_kinect_depth">
          <update_rate>${update_rate}</update_rate>
          <camera>
            <!-- 75x65 degree FOV for the depth sensor -->
            <horizontal_fov>${h_fov}</horizontal_fov>
            <vertical_fov>${v_fov}</vertical_fov>

            <!-- 90x59 degree FOV for the hardware color camera -->
            <!-- currently disabled, as this would mangle the depth data
            <horizontal_fov>1.5707963267948966</horizontal_fov>
            <vertical_fov>1.0297442586766543</vertical_fov>
            -->
            <image>
              <!--
                The Azure Kinect has a bit of a weird frame size for the depth data
                The color data is full-HD+, but that doesn't appear to be supported yet.
                see: https://docs.microsoft.com/en-us/azure/kinect-dk/hardware-specification
              -->
              <width>${width}</width>
              <height>${height}</height>
              <!-- TODO: check what format the Azure Kinect hardware delivers and set this to match! -->
              <format>RGB8</format>
            </image>
            <clip>
              <!-- give the color sensor a maximum range of 50m so that the simulation renders nicely -->
              <near>0.01</near>
              <far>50.0</far>
            </clip>
          </camera>
          <plugin name="kinect_controller" filename="libgazebo_ros_openni_kinect.so">
            <baseline>0.2</baseline>
            <alwaysOn>true</alwaysOn>
            <updateRate>0.0</updateRate>
            <cameraName>${topic}</cameraName>
            <imageTopicName>color/image_raw</imageTopicName>
            <cameraInfoTopicName>color/camera_info</cameraInfoTopicName>
            <depthImageTopicName>depth/image_raw</depthImageTopicName>
            <depthImageInfoTopicName>depth/camera_info</depthImageInfoTopicName>
            <pointCloudTopicName>depth/points</pointCloudTopicName>
            <frameName>${frame}_gazebo</frameName>
            <!-- the Azure Kinect has an effective depth-sensing range of 0.5m to 5.46m -->
            <pointCloudCutoff>${min_range}</pointCloudCutoff>
            <pointCloudCutoffMax>${max_range}</pointCloudCutoffMax>
            <distortionK1>0.00000001</distortionK1>
            <distortionK2>0.00000001</distortionK2>
            <distortionK3>0.00000001</distortionK3>
            <distortionT1>0.00000001</distortionT1>
            <distortionT2>0.00000001</distortionT2>
            <CxPrime>0</CxPrime>
            <Cx>0</Cx>
            <Cy>0</Cy>
            <focalLength>0</focalLength>
            <hackBaseline>0</hackBaseline>
          </plugin>
        </sensor>
      </gazebo>
    </xacro:macro>

    <!-- We assume the 3d-printed mounting plate is in use -->
    <link name="${prefix}_kinect_mount_plate">
      <visual>
        <origin xyz="0 0 0" rpy="0 0 0" />
        <geometry>
          <mesh filename="package://jackal_description/meshes/kinect_mount.stl"/>
        </geometry>
        <material name="black"/>
      </visual>
    </link>
    <joint name="${prefix}_kinect_mount_joint" type="fixed">
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <parent link="${parent_link}"/>
      <child link="${prefix}_kinect_mount_plate"/>
    </joint>

    <!-- this is the actual mounting hole in the mounting plate -->
    <joint name="${prefix}_kinect_mount_hole" type="fixed">
      <origin xyz="0.09 0 0.0335" rpy="0 -0.17453292519444444 0"/>
      <parent link="${prefix}_kinect_mount_plate"/>
      <child link="${prefix}_kinect_base"/>
    </joint>

    <xacro:azure_kinect frame="${prefix}_kinect" topic="${topic}"/>
  </xacro:macro>
</robot>
